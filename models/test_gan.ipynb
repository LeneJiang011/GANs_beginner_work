{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 784)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = mnist.train.images[:55000, :]\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\np5PxP4aIh7EAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1ee19e2cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "randomNum = random.randint(0, 55000)\n",
    "image = x_train[randomNum].reshape([28,28])\n",
    "plt.imshow(image, cmap=plt.get_cmap('gray_r'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(input=x, filter=W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def avg_pool_2x2(x):\n",
    "    return tf.nn.avg_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discriminator(x_image, reuse=False):\n",
    "    with tf.variable_scope('discriminator') as scope:\n",
    "        if(reuse):\n",
    "            tf.get_variable_scope().reuse_variables()\n",
    "        \n",
    "        # First conv and pool layers\n",
    "        W_conv1 = tf.get_variable('d_wconv1', [5, 5, 1, 8], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        b_conv1 = tf.get_variable('d_bconv1', [8], initializer=tf.constant_initializer(0))\n",
    "        h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "        h_pool1 = avg_pool_2x2(h_conv1)\n",
    "        \n",
    "        # Second conv and pool layers\n",
    "        W_conv2 = tf.get_variable('d_wconv2', [5, 5, 8, 16], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        b_conv2 = tf.get_variable('d_bconv2', [16], initializer=tf.constant_initializer(0))\n",
    "        h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "        h_pool2 = avg_pool_2x2(h_conv2)\n",
    "        \n",
    "        # First fully connected layer\n",
    "        W_fc1 = tf.get_variable('d_wfc1', [7 * 7 * 16, 32], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        b_fc1 = tf.get_variable('d_bfc1', [32], initializer=tf.constant_initializer(0))\n",
    "        h_pool2_flat = tf.reshape(h_pool2, [-1, 7 * 7 * 16])\n",
    "        h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "        \n",
    "        # Second fully connected layer\n",
    "        W_fc2 = tf.get_variable('d_wfc2', [32, 1], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        b_fc2 = tf.get_variable('d_bfc2', [1], initializer=tf.constant_initializer(0))\n",
    "        \n",
    "        # Final layer\n",
    "        y_conv = tf.matmul(h_fc1, W_fc2) + b_fc2\n",
    "        \n",
    "    return y_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator(z, batch_size, z_dim, reuse=False):\n",
    "    with tf.variable_scope('generator') as scope:\n",
    "        if (reuse):\n",
    "            tf.get_variable_scope().reuse_variables()\n",
    "        \n",
    "        g_dim = 64 # number of filters of first layer of generator\n",
    "        c_dim = 1 # color dimension of output\n",
    "        \n",
    "        s = 28\n",
    "        s2, s4, s8, s16 = int(s/2), int(s/4), int(s/8), int(s/16) # slowly upscale\n",
    "        h0 = tf.reshape(z, [batch_size, s16 + 1, s16 + 1, 25])\n",
    "        h0 = tf.nn.relu(h0)\n",
    "        # Dimensions of h0 = batch_size x 2 x 2 x 25\n",
    "        \n",
    "        # First deconv layer\n",
    "        output1_shape = [batch_size, s8, s8, g_dim * 4]\n",
    "        W_conv1 = tf.get_variable('g_wconv1', [5, 5, output1_shape[-1], int(h0.get_shape()[-1])], \n",
    "                                  initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "        b_conv1 = tf.get_variable('g_bconv1', [output1_shape[-1]], \n",
    "                                  initializer=tf.constant_initializer(.1))\n",
    "        H_conv1 = tf.nn.conv2d_transpose(h0, W_conv1, output_shape=output1_shape, \n",
    "                                        strides = [1, 2, 2, 1], padding='SAME')\n",
    "        H_conv1 = tf.contrib.layers.batch_norm(H_conv1, center = True, \n",
    "                                               scale = True, is_training = True, scope = 'g_bn1')\n",
    "        H_conv1 = tf.nn.relu(H_conv1)\n",
    "        # Dimensions of H_conv1 = batch_size x 3 x 3 x 256\n",
    "        \n",
    "        # Second Deconv layer\n",
    "        output2_shape = [batch_size, s4 - 1, s4 - 1, g_dim * 2]\n",
    "        W_conv2 = tf.get_variable('g_wconv2', [5, 5, output2_shape[-1], int(H_conv1.get_shape()[-1])], \n",
    "                                  initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "        b_conv2 = tf.get_variable('g_bconv2', [output2_shape[-1]], \n",
    "                                  initializer=tf.constant_initializer(.1))\n",
    "        H_conv2 = tf.nn.conv2d_transpose(H_conv1, W_conv2, output_shape=output2_shape, \n",
    "                                        strides = [1, 2, 2, 1], padding='SAME')\n",
    "        H_conv2 = tf.contrib.layers.batch_norm(H_conv2, center = True, \n",
    "                                               scale = True, is_training = True, scope = 'g_bn2')\n",
    "        H_conv2 = tf.nn.relu(H_conv2)\n",
    "        # Dimensions of H_conv2 = batch_size x 6 x 6 x 128\n",
    "        \n",
    "        # Third Deconv layer\n",
    "        output3_shape = [batch_size, s2 - 2, s2 - 2, g_dim * 1]\n",
    "        W_conv3 = tf.get_variable('g_wconv3', [5, 5, output3_shape[-1], int(H_conv2.get_shape()[-1])], \n",
    "                                  initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "        b_conv3 = tf.get_variable('g_bconv3', [output3_shape[-1]], \n",
    "                                  initializer=tf.constant_initializer(.1))\n",
    "        H_conv3 = tf.nn.conv2d_transpose(H_conv2, W_conv3, output_shape=output3_shape, \n",
    "                                        strides = [1, 2, 2, 1], padding='SAME')\n",
    "        H_conv3 = tf.contrib.layers.batch_norm(H_conv3, center = True, \n",
    "                                               scale = True, is_training = True, scope = 'g_bn3')\n",
    "        H_conv3 = tf.nn.relu(H_conv3)\n",
    "        # Dimensions of H_conv3 = batch_size x 12 x 12 x 64\n",
    "        \n",
    "        # Fourth Deconv layer\n",
    "        output4_shape = [batch_size, s, s, c_dim]\n",
    "        W_conv4 = tf.get_variable('g_wconv4', [5, 5, output4_shape[-1], int(H_conv3.get_shape()[-1])], \n",
    "                                  initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "        b_conv4 = tf.get_variable('g_bconv4', [output4_shape[-1]], \n",
    "                                  initializer=tf.constant_initializer(.1))\n",
    "        H_conv4 = tf.nn.conv2d_transpose(H_conv3, W_conv4, output_shape=output4_shape, \n",
    "                                        strides = [1, 2, 2, 1], padding='VALID')\n",
    "        H_conv4 = tf.nn.tanh(H_conv4)\n",
    "        # Dimensions of H_conv4 = batch_size x 28 x 28 x 1\n",
    "    \n",
    "    return H_conv4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "z_dimensions = 100\n",
    "\n",
    "sess = tf.Session()\n",
    "x_placeholder = tf.placeholder(\"float\", shape = [None, 28, 28, 1])\n",
    "z_placeholder = tf.placeholder(tf.float32, [None, z_dimensions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Dx = discriminator(x_placeholder)\n",
    "Gz = generator(z_placeholder, batch_size, z_dimensions)\n",
    "Dg = discriminator(Gz, reuse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=Dg, labels=tf.ones_like(Dg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=Dx, labels=tf.ones_like(Dx)))\n",
    "d_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=Dg, labels=tf.zeros_like(Dg)))\n",
    "d_loss = d_loss_real + d_loss_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tvars = tf.trainable_variables()\n",
    "d_vars = [var for var in tvars if 'd_' in var.name]\n",
    "g_vars = [var for var in tvars if 'g_' in var.name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope(tf.get_variable_scope(), reuse=False):\n",
    "    trainerD = tf.train.AdamOptimizer(learning_rate=.0002).minimize(d_loss, var_list=d_vars)\n",
    "    trainerG = tf.train.AdamOptimizer(learning_rate=.0002).minimize(g_loss, var_list=g_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0000 dcost= 0.086642161\n",
      "Iteration: 0000 gcost= 0.043320332\n",
      "Iteration: 0100 dcost= 0.082871966\n",
      "Iteration: 0100 gcost= 0.057025306\n",
      "Iteration: 0200 dcost= 0.085528173\n",
      "Iteration: 0200 gcost= 0.043786488\n",
      "Iteration: 0300 dcost= 0.086154118\n",
      "Iteration: 0300 gcost= 0.044649407\n",
      "Iteration: 0400 dcost= 0.086341321\n",
      "Iteration: 0400 gcost= 0.042208500\n",
      "Iteration: 0500 dcost= 0.086806297\n",
      "Iteration: 0500 gcost= 0.043623418\n",
      "Iteration: 0600 dcost= 0.085868388\n",
      "Iteration: 0600 gcost= 0.047801886\n",
      "Iteration: 0700 dcost= 0.086742595\n",
      "Iteration: 0700 gcost= 0.041440599\n",
      "Iteration: 0800 dcost= 0.088146441\n",
      "Iteration: 0800 gcost= 0.038481563\n",
      "Iteration: 0900 dcost= 0.085770242\n",
      "Iteration: 0900 gcost= 0.050000992\n",
      "Iteration: 1000 dcost= 0.081794120\n",
      "Iteration: 1000 gcost= 0.044594049\n",
      "Iteration: 1100 dcost= 0.084386125\n",
      "Iteration: 1100 gcost= 0.041500956\n",
      "Iteration: 1200 dcost= 0.068996117\n",
      "Iteration: 1200 gcost= 0.048544697\n",
      "Iteration: 1300 dcost= 0.058611054\n",
      "Iteration: 1300 gcost= 0.066119976\n",
      "Iteration: 1400 dcost= 0.052803196\n",
      "Iteration: 1400 gcost= 0.073955193\n",
      "Iteration: 1500 dcost= 0.031702507\n",
      "Iteration: 1500 gcost= 0.108794488\n",
      "Iteration: 1600 dcost= 0.025531635\n",
      "Iteration: 1600 gcost= 0.101912603\n",
      "Iteration: 1700 dcost= 0.024627820\n",
      "Iteration: 1700 gcost= 0.109898724\n",
      "Iteration: 1800 dcost= 0.033878855\n",
      "Iteration: 1800 gcost= 0.147021919\n",
      "Iteration: 1900 dcost= 0.017849235\n",
      "Iteration: 1900 gcost= 0.109428488\n",
      "Iteration: 2000 dcost= 0.011907911\n",
      "Iteration: 2000 gcost= 0.128460273\n",
      "Iteration: 2100 dcost= 0.072462991\n",
      "Iteration: 2100 gcost= 0.131901622\n",
      "Iteration: 2200 dcost= 0.094658449\n",
      "Iteration: 2200 gcost= 0.062814839\n",
      "Iteration: 2300 dcost= 0.048511837\n",
      "Iteration: 2300 gcost= 0.086688347\n",
      "Iteration: 2400 dcost= 0.018358979\n",
      "Iteration: 2400 gcost= 0.107620537\n",
      "Iteration: 2500 dcost= 0.019045684\n",
      "Iteration: 2500 gcost= 0.138658807\n",
      "Iteration: 2600 dcost= 0.029927559\n",
      "Iteration: 2600 gcost= 0.139421195\n",
      "Iteration: 2700 dcost= 0.016162351\n",
      "Iteration: 2700 gcost= 0.148218095\n"
     ]
    }
   ],
   "source": [
    "sess.run(tf.global_variables_initializer())\n",
    "iterations = 3000\n",
    "for i in range(iterations):\n",
    "    avg_dcost = 0\n",
    "    avg_gcost = 0\n",
    "    z_batch = np.random.normal(-1, 1, size=[batch_size, z_dimensions])\n",
    "    real_image_batch = mnist.train.next_batch(batch_size)\n",
    "    real_image_batch = np.reshape(real_image_batch[0], [batch_size, 28, 28, 1])\n",
    "    \n",
    "    _, dLoss = sess.run([trainerD, d_loss], feed_dict={z_placeholder: z_batch, \n",
    "                                                       x_placeholder: real_image_batch})\n",
    "    avg_dcost += dLoss / batch_size\n",
    "    if (i % 100 == 0):\n",
    "        print(\"Iteration:\", '%04d' % (i), \"dcost=\", \"{:.9f}\".format(avg_dcost))\n",
    "    \n",
    "    _, gLoss = sess.run([trainerG, g_loss], feed_dict={z_placeholder: z_batch})\n",
    "    avg_gcost += gLoss / batch_size\n",
    "    if (i % 100 == 0):\n",
    "        print(\"Iteration:\", '%04d' % (i), \"gcost=\", \"{:.9f}\".format(avg_gcost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f0968071c88>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_image = generator(z_placeholder, 1, z_dimensions, reuse=True)\n",
    "z_batch = np.random.normal(-1, 1, size=[1, z_dimensions])\n",
    "temp = (sess.run(sample_image, feed_dict={z_placeholder: z_batch}))\n",
    "my_i = temp.squeeze()\n",
    "plt.imshow(my_i, cmap='gray_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0968108860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
