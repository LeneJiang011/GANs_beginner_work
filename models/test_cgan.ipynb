{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 784)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = mnist.train.images[:55000, :]\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEBThB4Ii/EBQhB8I6i8iN1HWY49qEgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9e533a3e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "randomNum = random.randint(0, 55000)\n",
    "image = x_train[randomNum].reshape([28,28])\n",
    "plt.imshow(image, cmap=plt.get_cmap('gray_r'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_dim = 10\n",
    "channel = 1\n",
    "batch_size = 16\n",
    "z_dimensions = 100\n",
    "EPOCH = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LeakyReLU\n",
    "def lrelu(x, alpha=0.2):\n",
    "    return tf.maximum(x, alpha*x)\n",
    "\n",
    "def conv2d(x, W, b):\n",
    "    out = tf.nn.conv2d(x, W, strides=[1, 2, 2, 1], padding='SAME')\n",
    "    return tf.nn.bias_add(out, b)\n",
    "\n",
    "def de_conv(x, W, b, out_shape):\n",
    "    with tf.name_scope('deconv') as scope:\n",
    "        deconv = tf.nn.conv2d_transpose(x, W, out_shape, [1, 2, 2, 1], \n",
    "                                        padding='SAME', name=None)\n",
    "        out = tf.nn.bias_add(deconv, b)\n",
    "        return out\n",
    "    \n",
    "def fully_connect(x, W, b):\n",
    "    return tf.add(tf.matmul(x, W), b)\n",
    "\n",
    "# Concatenate x and y\n",
    "def conv_cond_concat(x, y):\n",
    "    x_shapes = x.get_shape()\n",
    "    y_shapes = y.get_shape()\n",
    "    print(x_shapes)\n",
    "    print(y_shapes)\n",
    "    return tf.concat([x, y * tf.ones([x_shapes[0], x_shapes[1], \n",
    "                                      x_shapes[2], y_shapes[3]])], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discriminator(x_image, y, reuse=False):\n",
    "    with tf.variable_scope('discriminator') as scope:\n",
    "        if(reuse):\n",
    "            tf.get_variable_scope().reuse_variables()\n",
    "        \n",
    "        yb = tf.reshape(y, shape=[batch_size, 1, 1, y_dim])\n",
    "        input_array = conv_cond_concat(x_image, yb)\n",
    "        \n",
    "        # First conv layers\n",
    "        W_conv1 = tf.Variable(tf.random_normal([5, 5, 11, 10], stddev=0.02), \n",
    "                              name='d_wconv1')\n",
    "        b_conv1 = tf.Variable(tf.zeros([10]), \n",
    "                              name='d_bconv1' )\n",
    "        h_conv1 = conv2d(input_array, W_conv1, b_conv1)\n",
    "        h_conv1 = lrelu(h_conv1)\n",
    "        h_conv1 = conv_cond_concat(h_conv1, yb)        \n",
    "        \n",
    "        # Second conv layers\n",
    "        W_conv2 = tf.Variable(tf.random_normal([5, 5, 20, 64], stddev=0.02), \n",
    "                              name='d_wconv2')\n",
    "        b_conv2 = tf.Variable(tf.zeros([64]), \n",
    "                              name='d_bconv2' )\n",
    "        h_conv2 = conv2d(h_conv1, W_conv2, b_conv2)\n",
    "        h_conv2 = tf.contrib.layers.batch_norm(h_conv2, center = True, \n",
    "                                               scale = True, is_training = True, scope = 'd_bn1')\n",
    "        h_conv2 = lrelu(h_conv2)\n",
    "        h_conv2 = tf.reshape(h_conv2, [batch_size, -1])\n",
    "        h_conv2 = tf.concat([h_conv2, y], 1)\n",
    "        \n",
    "    \n",
    "        # First fully connected layer\n",
    "        W_fc1 = tf.Variable(tf.random_normal([7 * 7 * 64 + y_dim, 1024], stddev=0.02),\n",
    "                            name='d_wfc1')\n",
    "        b_fc1 = tf.Variable(tf.zeros([1024]), name='d_bfc1')\n",
    "        h_fc1 = fully_connect(h_conv2, W_fc1, b_fc1)\n",
    "        h_fc1 = tf.contrib.layers.batch_norm(h_fc1, center = True, \n",
    "                                               scale = True, is_training = True, scope = 'd_bn2')\n",
    "        h_fc1 = lrelu(h_fc1)\n",
    "        h_fc1 = tf.concat([h_fc1, y], 1)\n",
    "        \n",
    "        # Final layer\n",
    "        W_fc2 = tf.Variable(tf.random_normal([1024 + y_dim, channel], stddev=0.02), \n",
    "                            name='d_wfc2')\n",
    "        b_fc2 = tf.Variable(tf.zeros([channel]), \n",
    "                            name='d_bfc2')\n",
    "        H_fc2 = fully_connect(h_fc1, W_fc2, b_fc2)\n",
    "        H_fc2 = tf.nn.sigmoid(H_fc2)\n",
    "        \n",
    "    return H_fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator(batch_size, z, z_dimensions, y, reuse=False):\n",
    "    with tf.variable_scope('generator') as scope:\n",
    "        if (reuse):\n",
    "            tf.get_variable_scope().reuse_variables()\n",
    "        \n",
    "        yb = tf.reshape(y, shape=[batch_size, 1, 1, y_dim])\n",
    "        z = tf.concat([z, y], 1)\n",
    "        output_size = 28\n",
    "        c1, c2 = int(output_size/4), int(output_size/2)\n",
    "    \n",
    "        \n",
    "        # First fully connected layer\n",
    "        W_fc1 = tf.Variable(tf.random_normal([z_dimensions + y_dim, 1024], stddev=0.02), \n",
    "                            name='g_wfc1')\n",
    "        b_fc1 = tf.Variable(tf.zeros([1024]), \n",
    "                            name='g_wfc1')\n",
    "        H_fc1 = fully_connect(z, W_fc1, b_fc1)\n",
    "        H_fc1 = tf.contrib.layers.batch_norm(H_fc1, center = True, \n",
    "                                               scale = True, is_training = True, scope = 'g_bn1')\n",
    "        H_fc1 = tf.nn.relu(H_fc1)\n",
    "        H_fc1 = tf.concat([H_fc1, y], 1)\n",
    "        \n",
    "        \n",
    "        # Second fully connected layer\n",
    "        W_fc2 = tf.Variable(tf.random_normal([1024 + y_dim, 7 * 7 * 2 * 64], stddev=0.02), \n",
    "                            name='g_wfc2')\n",
    "        b_fc2 = tf.Variable(tf.zeros([7 * 7 * 2 * 64]), \n",
    "                            name='g_wfc2')\n",
    "        H_fc2 = fully_connect(H_fc1, W_fc2, b_fc2)\n",
    "        H_fc2 = tf.contrib.layers.batch_norm(H_fc2, center = True, \n",
    "                                               scale = True, is_training = True, scope = 'g_bn2')\n",
    "        H_fc2 = tf.nn.relu(H_fc2)\n",
    "        H_fc2 = tf.reshape(H_fc2, [batch_size, c1, c1, 64 * 2])\n",
    "        H_fc2 = conv_cond_concat(H_fc2, yb)\n",
    "        \n",
    "        # First Deconv layer\n",
    "        W_conv1 = tf.Variable(tf.random_normal([5, 5, 128, 138], stddev=0.02), \n",
    "                              name='g_wconv1')\n",
    "        b_conv1 = tf.Variable(tf.zeros([128]), \n",
    "                              name='g_bconv1')\n",
    "        H_conv1 = de_conv(H_fc2, W_conv1, b_conv1, out_shape=[batch_size, c2, c2, 128])\n",
    "        H_conv1 = tf.contrib.layers.batch_norm(H_conv1, center = True, \n",
    "                                               scale = True, is_training = True, scope = 'g_bn3')\n",
    "        H_conv1 = tf.nn.relu(H_conv1)\n",
    "        H_conv1 = conv_cond_concat(H_conv1, yb)\n",
    "        \n",
    "        # Second Deconv layer\n",
    "        W_conv2 = tf.Variable(tf.random_normal([5, 5, channel, 138], stddev=0.02), \n",
    "                              name='g_wconv2')\n",
    "        b_conv2 = tf.Variable(tf.zeros([channel]), \n",
    "                              name='g_bconv2')\n",
    "        H_conv2 = de_conv(H_conv1, W_conv2, b_conv2, out_shape=[batch_size, output_size, output_size, 1])\n",
    "        H_conv2 = tf.nn.sigmoid(H_conv2)\n",
    "    \n",
    "    return H_conv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "images = tf.placeholder(tf.float32, [batch_size, 28, 28, 1])\n",
    "y_placeholder = tf.placeholder(tf.float32, [None, y_dim])\n",
    "z_placeholder = tf.placeholder(tf.float32, [None, z_dimensions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 28, 28, 1)\n",
      "(16, 1, 1, 10)\n",
      "(16, 14, 14, 10)\n",
      "(16, 1, 1, 10)\n",
      "(16, 7, 7, 128)\n",
      "(16, 1, 1, 10)\n",
      "(16, 14, 14, 128)\n",
      "(16, 1, 1, 10)\n",
      "(16, 28, 28, 1)\n",
      "(16, 1, 1, 10)\n",
      "(16, 14, 14, 10)\n",
      "(16, 1, 1, 10)\n"
     ]
    }
   ],
   "source": [
    "Dx = discriminator(images, y_placeholder)\n",
    "Gz = generator(batch_size, z_placeholder, z_dimensions, y_placeholder)\n",
    "Dg = discriminator(Gz, y_placeholder, reuse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=Dg, labels=tf.ones_like(Dg)))\n",
    "d_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=Dx, labels=tf.ones_like(Dx)))\n",
    "d_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=Dg, labels=tf.zeros_like(Dg)))\n",
    "d_loss = d_loss_real + d_loss_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tvars = tf.trainable_variables()\n",
    "d_vars = [var for var in tvars if 'd_' in var.name]\n",
    "g_vars = [var for var in tvars if 'g_' in var.name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope(tf.get_variable_scope(), reuse=False):\n",
    "    trainerD = tf.train.AdamOptimizer(learning_rate=.0002, beta1=0.5).minimize(d_loss, var_list=d_vars)\n",
    "    trainerG = tf.train.AdamOptimizer(learning_rate=.0002, beta1=0.5).minimize(g_loss, var_list=g_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0000 dcost= 0.093469054\n",
      "Iteration: 0000 gcost= 0.031238418\n",
      "Iteration: 0100 dcost= 0.068552777\n",
      "Iteration: 0100 gcost= 0.040110439\n",
      "Iteration: 0200 dcost= 0.067901477\n",
      "Iteration: 0200 gcost= 0.040312417\n",
      "Iteration: 0300 dcost= 0.070246994\n",
      "Iteration: 0300 gcost= 0.038859352\n",
      "Iteration: 0400 dcost= 0.065422475\n",
      "Iteration: 0400 gcost= 0.041787632\n",
      "Iteration: 0500 dcost= 0.067778975\n",
      "Iteration: 0500 gcost= 0.040344141\n",
      "Iteration: 0600 dcost= 0.067774743\n",
      "Iteration: 0600 gcost= 0.040345099\n",
      "Iteration: 0700 dcost= 0.067765184\n",
      "Iteration: 0700 gcost= 0.040348005\n",
      "Iteration: 0800 dcost= 0.065352693\n",
      "Iteration: 0800 gcost= 0.041822147\n",
      "Iteration: 0900 dcost= 0.070187405\n",
      "Iteration: 0900 gcost= 0.038867380\n",
      "Iteration: 1000 dcost= 0.062989578\n",
      "Iteration: 1000 gcost= 0.043265358\n",
      "Iteration: 1100 dcost= 0.062926285\n",
      "Iteration: 1100 gcost= 0.043303750\n",
      "Iteration: 1200 dcost= 0.062933505\n",
      "Iteration: 1200 gcost= 0.043299623\n",
      "Iteration: 1300 dcost= 0.062929258\n",
      "Iteration: 1300 gcost= 0.043300487\n",
      "Iteration: 1400 dcost= 0.062917620\n",
      "Iteration: 1400 gcost= 0.043309003\n",
      "Iteration: 1500 dcost= 0.062909991\n",
      "Iteration: 1500 gcost= 0.043315545\n",
      "Iteration: 1600 dcost= 0.062911406\n",
      "Iteration: 1600 gcost= 0.043314360\n",
      "Iteration: 1700 dcost= 0.062908106\n",
      "Iteration: 1700 gcost= 0.043316849\n",
      "Iteration: 1800 dcost= 0.062906198\n",
      "Iteration: 1800 gcost= 0.043318108\n",
      "Iteration: 1900 dcost= 0.062906407\n",
      "Iteration: 1900 gcost= 0.043318257\n",
      "Iteration: 2000 dcost= 0.062905580\n",
      "Iteration: 2000 gcost= 0.043318409\n",
      "Iteration: 2100 dcost= 0.062906533\n",
      "Iteration: 2100 gcost= 0.043318152\n",
      "Iteration: 2200 dcost= 0.062906176\n",
      "Iteration: 2200 gcost= 0.043318488\n",
      "Iteration: 2300 dcost= 0.062904440\n",
      "Iteration: 2300 gcost= 0.043319181\n",
      "Iteration: 2400 dcost= 0.062903926\n",
      "Iteration: 2400 gcost= 0.043319650\n",
      "Iteration: 2500 dcost= 0.062904209\n",
      "Iteration: 2500 gcost= 0.043319479\n",
      "Iteration: 2600 dcost= 0.062903918\n",
      "Iteration: 2600 gcost= 0.043319702\n",
      "Iteration: 2700 dcost= 0.062903419\n",
      "Iteration: 2700 gcost= 0.043319948\n",
      "Iteration: 2800 dcost= 0.062907420\n",
      "Iteration: 2800 gcost= 0.043316990\n",
      "Iteration: 2900 dcost= 0.062902704\n",
      "Iteration: 2900 gcost= 0.043320473\n"
     ]
    }
   ],
   "source": [
    "sess.run(tf.global_variables_initializer())\n",
    "iterations = 3000\n",
    "for i in range(iterations):\n",
    "    avg_dcost = 0\n",
    "    avg_gcost = 0\n",
    "    z_batch = np.random.normal(-1, 1, size=[batch_size, z_dimensions])\n",
    "    real_image_batch = mnist.train.next_batch(batch_size)\n",
    "    input_image_batch = np.reshape(real_image_batch[0], \n",
    "                                   [batch_size, 28, 28, 1])\n",
    "    input_label_batch = np.reshape(real_image_batch[1],\n",
    "                                   [batch_size, y_dim])\n",
    "    \n",
    "    _, dLoss = sess.run([trainerD, d_loss], feed_dict={images: input_image_batch,\n",
    "                                                        y_placeholder: input_label_batch,\n",
    "                                                        z_placeholder: z_batch})\n",
    "    avg_dcost += dLoss / batch_size\n",
    "    if (i % 100 == 0):\n",
    "        print(\"Iteration:\", '%04d' % (i), \"dcost=\", \"{:.9f}\".format(avg_dcost))\n",
    "    \n",
    "    _, gLoss = sess.run([trainerG, g_loss], feed_dict={y_placeholder: input_label_batch,\n",
    "                                                       z_placeholder: z_batch})\n",
    "    \n",
    "    avg_gcost += gLoss / batch_size\n",
    "    if (i % 100 == 0):\n",
    "        print(\"Iteration:\", '%04d' % (i), \"gcost=\", \"{:.9f}\".format(avg_gcost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 7, 7, 128)\n",
      "(1, 1, 1, 10)\n",
      "(1, 14, 14, 128)\n",
      "(1, 1, 1, 10)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9deb56be48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_label = mnist.train.labels\n",
    "randomNum = random.randint(0, 55000)\n",
    "test_y = test_label[randomNum].reshape([1,10])\n",
    "\n",
    "sample_image = generator(1, z_placeholder, z_dimensions, y_placeholder, reuse=True)\n",
    "test_z = np.random.normal(-1, 1, [1, z_dimensions])\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "temp = (sess.run(sample_image, feed_dict={y_placeholder: test_y,\n",
    "                                          z_placeholder: test_z}))\n",
    "\n",
    "my_i = temp.squeeze()\n",
    "plt.imshow(my_i, cmap='gray_r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
