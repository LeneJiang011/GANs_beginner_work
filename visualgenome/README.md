PAPER & CODE & ANALYSIS  

## [VisualGenome](http://visualgenome.org/)  
* image to language  

## [Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image Annotations](http://visualgenome.org/paper)  
### Abstract  
TO understand the interactions and relationships between objects in an image.  
Each image has an average of 21 objects, 18 attributes, and 18 pairwise relationships between objects.  

### Introduction  
* Comprehensive Scene Understanding: Objects, attributes, relationships and interactions.  
* Three key elements: a grounding of visual concepts to language, a more complete set of descriptions and QAs, and a formalized representation of the components of an image.  

### Visual Genome Data Representation  
Consists of seven main components: region descriptions, objects, attributes, relationships, region graphs, scene graphs, and question answer pairs.  
* computer-generated image region descriptions with bounding boxes.  
* 6 different questions per image: what, where, how, when, who, and why.

### Future Applications  
* Dense image captioning: describe parts of the scene  
* Visual question answering
* Image understanding: evaluation metrics  
* Relationship extraction: also in action recognitin and spatial orientation between objects  
* **Semantic** image retrieval: improve semantic image search  

### Conclusion  
* provide a multi-layer understanding of pictures  
* A large formalized knowledge representation for visual understanding and a more complete set of descriptions and question answers that grouds visual concepts to language.  
